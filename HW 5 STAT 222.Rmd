---
title: "STAT 222 Spring 2021 HW5"
author: "Matthew Zhao"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
header-includes: \usepackage{pdfpages}
geometry: margin = .65in
fontsize: 12pt
---

```{r include=F}
library(knitr)
knitr::opts_chunk$set(fig.width=4, fig.height=3.5, message=F, warning=F, collapse=T)
options(scipen=6, digits=5)
```


## Question 1

```{r}
insulate = read.table("http://www.stat.uchicago.edu/~yibi/s222/insulate.txt", h=T)
```


### Q1a --- 4 points

```{r}
m1 = lm(failtime~as.factor(material),data=insulate)
m2 = lm(log(failtime) ~ as.factor(material), data=insulate)
```
```{r}
qqnorm(m1$residuals)
qqline(m1$residuals)
qqnorm(m2$residuals)
qqline(m2$residuals)
```


These graphs suggest that our assumption that the data are not normally distributed is incorrect, since prior to transforming the response (failtime), the points did not fall on the line. After the log transformation of the response, the points fell on the line. 

### Q1b --- 2 points


```{r}
library(emmeans)
summary(emmeans(m1, "material", level=0.95))
```

```{r}
summary(emmeans(m2, "material", level=0.95))
exp(summary(emmeans(m2, "material", level=0.95))[,5:6])
```


I believe that the second method is more reasonable because the m1 model violates our assumption of normal data and specifically has non-constant variance. As a result, the confidence intervals generated using this data would be incorrect since they were created assuming normal data. Since the data from the m2 model was normalized and then reverted, I would trust these confidence intervals more.


## Question 2

```{r}
logging = read.table("http://www.stat.uchicago.edu/~yibi/s222/logging.txt", h=T)
```


### Q2a --- 2 points


```{r, fig.width=3, fig.height=2.8, out.width='30%'}
library(ggplot2)
ggplot(logging, aes(x=condition, y=nitrate)) + geom_boxplot()
```
```{r, fig.width=3, fig.height=2.8, out.width='30%'}
model = lm(nitrate~as.factor(condition),data=logging)
qqnorm(model$residuals)
qqline(model$residuals)
```


Right-skewed. This is confirmed by the boxplots which have large 75 percentiles far from the 50 percentiles. 

### Q2b --- 4 points


```{r}
logging$lognitrate = log(10+logging$nitrate)
lmlog = lm(lognitrate ~ condition, data=logging)
```
```{r}
ggplot(data = lmlog, aes(x = lmlog$fitted.values, y = lmlog$residuals)) +
  geom_point() + labs(x = "Fitted Values", y = "Residuals")
qqnorm(lmlog$residuals)
qqline(lmlog$residuals)

```


The plots tell us that both assumptions are false. The constant variability assumption is violated since the first group of fitted values has a lower variance than the second group of fitted values. The normality assumption is violated since the points do not fall on the line of the normal qq plot. 

### Q2c --- 2 points

```{r,  fig.width=7, fig.height=2.5}
library(ggplot2)
ggplot(logging, aes(x=week, y=lmlog$res)) +
  geom_point() + geom_line() +
  facet_wrap(~condition, nrow=2)
```


The graph for Undisturbed is fairly smooth, indicating positive autocorrelation and that there is serial dependence. The Patch-cut has smooth patches especially towards the beginning, indicating that there is also serial dependence. 

### Q2d --- 2 points


```{r, fig.width=5, fig.height=3, fig.show='hold', out.width=c('35%', '35%')}
res.patch = subset(lmlog$res, logging$condition == "Patch-cut")
res.undisturb = subset(lmlog$res, logging$condition == "Undisturbed")
par(mai=c(.6,.6,.3,.01),mgp=c(2,.7,0))
plot(res.patch[1:87], res.patch[2:88], ylab="Current Residuals", 
      xlab="Lag 1 Residuals", main="Patch-Cut")
cor(res.patch[1:87], res.patch[2:88])

plot(res.undisturb[1:87], res.undisturb[2:88], ylab="Current Residuals", 
      xlab="Lag 1 Residuals", main="Undisturbed")
cor(res.undisturb[1:87], res.undisturb[2:88])
```


Both plots exhibit a weak positive correlation, indicating serial dependence.

### Q2e --- 2 points

I do not. This is because the data violates a number of our assumptions, meaning a standard ANOVA F-test is not suitable. Specifically, because the data show serial dependence (positive autocorrelation), the MSE will underestimate the actual variance of the noise. This will cause the F statistic to be artificially large and make it more likely that we will have a lower p value and reject the null i.e. the likelihood of Type I Error is higher.

## Question 3


```{r fig.width=7.5, fig.height=4.3}
wheat56 = read.table("http://www.stat.uchicago.edu/~yibi/s222/wheat56.txt", h=T)
par(mai=c(.6,.6,.3,.1),mgp=c(2,.7,0))    # reducing the margin of plot
plot(wheat56$Longitude, wheat56$Latitude, type="n",
     xlab="Longitude", ylab="Latitude", main="Number on Each Plot = Wheat Variety ID")
for(i in 0:22){abline(v=i+0.5, lty=2)}   # adding the vertical grid lines
for(j in 0:11){abline(h=j+0.5, lty=2)}   # adding the horizontal grid lines
text(wheat56$Longitude, wheat56$Latitude, labels = wheat56$Variety, cex=0.75)
```

```{r}
lmwheat = lm(Yield ~ as.factor(Variety), data = wheat56)
```


### Q3a --- 2 points


```{r fig.width=8, fig.height=4.5}
par(mai=c(.6,.6,.3,.1),mgp=c(2,.7,0)) # reducing the margin of plot
plot(wheat56$Longitude, wheat56$Latitude, type="n", 
     xlab="Longitude", ylab="Latitude", main="Studentized Residual for Each Plot")
for(i in 0:22){abline(v=i+0.5, lty=2)} # adding the vertical grid lines
for(j in 0:11){abline(h=j+0.5, lty=2)} # adding the horizontal grid lines
text(wheat56$Longitude, wheat56$Latitude, 
     labels = round(rstudent(lmwheat),1), cex=0.75, 
     col = 1+(rstudent(lmwheat)>0))
```




### Q3b --- 1 point


```{r}
res.array = array(NA, dim = c(22,11))
for(i in 1:22){
  for(j in 1:11){
    if(sum(wheat56$Longitude == i & wheat56$Latitude == j)>0){
      res.array[i,j] = rstudent(lmwheat)[wheat56$Longitude == i & wheat56$Latitude == j]
    }
  }
}
round(res.array, digits=1)
```


```{r, fig.width=3, fig.height=2.6}
par(mai=c(.6,.6,.1,.1),mgp=c(2,.7,0))   # for reducing the margin of plots
plot(as.vector(res.array[1:21,1:11]),as.vector(res.array[2:22,1:11]), 
     xlab="e[i-1,j]", ylab="e[i,j]")
cor(as.vector(res.array[1:21,1:11]),as.vector(res.array[2:22,1:11]), 
    use="complete.obs")
```



### Q3c --- 3 points

